{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3179ac01-64f9-4fbd-b4ab-bf41ced836ff",
   "metadata": {},
   "source": [
    "# Reinforcement Learning\n",
    "\n",
    "Im Gegensatz zum konventionellen ML wird beim RL kein vorgegebenes Datenset verwendet\n",
    "\n",
    "Beim RL gibt es einen Prozess der erlernt werden soll, während des Prozesses werden die Daten erzeugt\n",
    "\n",
    "Prozess:\n",
    "- Was soll gelernt werden?\n",
    "    - Reale Prozesse (Roboter)\n",
    "    - Softwareprozesse (Spiele)\n",
    " \n",
    "Umgebung:\n",
    "- Der Prozess selbst\n",
    "- Enthält Funktionen, welche der Agent verwenden kann, um den Prozess auszuführen\n",
    "\n",
    "Agent:\n",
    "- \"Der Akteur\", welcher den Prozess ausführt\n",
    "- Lernt aus den Daten, welche vom Prozess erzeugt werden\n",
    "\n",
    "Pakete:\n",
    "- Gym(nasium)\n",
    "- Stable Baselines 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3d29ae9-3ab0-44a6-8228-a18ee301b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d23a80-f8e3-4728-9cef-6881527cd389",
   "metadata": {},
   "source": [
    "## Vorgegebene Umgebung\n",
    "\n",
    "Innerhalb von Gym gibt es verschiedene Testumgebungen, um RL zu probieren\n",
    "\n",
    "Eine davon heißt CartPole-V1\n",
    "\n",
    "Es geht darum ein Kart zu bewegen, um eine darauf angebrachte Stange gerade zu halten\n",
    "\n",
    "https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45bc42da-dcf3-49e4-b828-0f731ae65fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b35dc2f-53fc-43e8-9755-b1bdfa726ebd",
   "metadata": {},
   "source": [
    "### Inhalte einer Umgebung\n",
    "\n",
    "Daten:\n",
    "- Action Space: Gibt dem Agenten vor, was er tun kann\n",
    "| Num | Action                 |\n",
    "|-----|------------------------|\n",
    "| 0   | Push cart to the left  |\n",
    "| 1   | Push cart to the right |\n",
    " \n",
    "- Observation Space: Gibt die Daten vor, welche für das ML verwendet können\n",
    "\n",
    "| Num | Observation           | Min                 | Max               |\n",
    "|-----|-----------------------|---------------------|-------------------|\n",
    "| 0   | Cart Position         | -4.8                | 4.8               |\n",
    "| 1   | Cart Velocity         | -Inf                | Inf               |\n",
    "| 2   | Pole Angle            | ~ -0.418 rad (-24°) | ~ 0.418 rad (24°) |\n",
    "| 3   | Pole Angular Velocity | -Inf                | Inf               |\n",
    "\n",
    "---\n",
    "\n",
    "Funktionen der Umgebung:\n",
    "- step: Bringt den Prozess um einen Schritt weiter\n",
    "- reset: Setzt die Umgebung auf den Anfangszustand zurück\n",
    "- render: Zeichnet die Umgebung (optional)\n",
    "- close: Wird ausgeführt, wenn die Umgebung abgebaut wird (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bea2a7d9-2e78-4f4a-bc7b-7e51f6cd5145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchgang: 0, Score: 86.0\n",
      "Durchgang: 1, Score: 12.0\n",
      "Durchgang: 2, Score: 33.0\n",
      "Durchgang: 3, Score: 19.0\n",
      "Durchgang: 4, Score: 18.0\n"
     ]
    }
   ],
   "source": [
    "durchgaenge = 5\n",
    "for d in range(durchgaenge):\n",
    "    start = env.reset()  # Am Anfang von jedem Durchgang wird die Umgebung zurückgesetzt\n",
    "    score = 0  # Summiert die Belohnung nach jedem Step auf\n",
    "    done = False\n",
    "\n",
    "    while not done:  # Führe die Umgebung aus, bis die step Methode True zurück gibt\n",
    "        env.render()  # Umgebung zeichnen\n",
    "        action = env.action_space.sample()  # Wähle eine zufällige Action, und füge diese bei step ein\n",
    "        newState, reward, done, term, info = env.step(action)  # Führe die Umgebung einmal aus\n",
    "        score += reward\n",
    "    print(f\"Durchgang: {d}, Score: {score}\")\n",
    "env.close()  # Fenster schließen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc6e1bc-4ada-4e29-bb36-bf36407446f0",
   "metadata": {},
   "source": [
    "Dieser Agent wählt zufällige Actions\n",
    "\n",
    "Hier soll jetzt ein ML Modell dahinterstehen, welches sinnvolle Actions auswählt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30247d-e59b-4bfb-b93f-6fe83050c1e5",
   "metadata": {},
   "source": [
    "## RL Modell trainieren\n",
    "\n",
    "Stable Baselines 3 stellt uns einige vordefinierte Algorithmen bereit\n",
    "\n",
    "Einer davon ist PPO (Proximal Policy Optimization)\n",
    "\n",
    "Wir benötigen zusätzlich noch eine Policy (definiert, wie das unterliegende Tensorflow Modell aussieht)\n",
    "\n",
    "Zusatz: DummyVecEnv, ermöglicht Parallelisierung des Lernprozesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26aa1709-230d-44b6-a0b0-6d7cf89762bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16aae68e-489e-465e-9d69-1aa8c2273d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b9f8179-7541-4ffa-957b-62a36b499427",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 983  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 2    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 480         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008324099 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | -0.00605    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.04        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0098     |\n",
      "|    value_loss           | 46.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 429          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075450065 |\n",
      "|    clip_fraction        | 0.042        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.667       |\n",
      "|    explained_variance   | 0.11         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0145      |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 402          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076680593 |\n",
      "|    clip_fraction        | 0.0726       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.637       |\n",
      "|    explained_variance   | 0.282        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0172      |\n",
      "|    value_loss           | 54           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 396         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009529585 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.603      |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 60.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009262935 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.597      |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 60.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 397          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035439276 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.577       |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 29.1         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    value_loss           | 58.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 397          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053752474 |\n",
      "|    clip_fraction        | 0.0392       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.566       |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.36         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00679     |\n",
      "|    value_loss           | 41.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 393         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004247962 |\n",
      "|    clip_fraction        | 0.0412      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.557      |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    value_loss           | 41.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 392          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033167838 |\n",
      "|    clip_fraction        | 0.0283       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.539       |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.78         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    value_loss           | 35.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 392         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011473909 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.536      |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.714       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 10.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 387         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009905281 |\n",
      "|    clip_fraction        | 0.0639      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.537      |\n",
      "|    explained_variance   | 0.81        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.11        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 385        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 69         |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00405894 |\n",
      "|    clip_fraction        | 0.0342     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.54      |\n",
      "|    explained_variance   | 0.777      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0622     |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.00204   |\n",
      "|    value_loss           | 4.4        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 386          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066674324 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.544       |\n",
      "|    explained_variance   | 0.17         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.168        |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    value_loss           | 2.77         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 378          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044625467 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.523       |\n",
      "|    explained_variance   | -0.0266      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.155        |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.000777    |\n",
      "|    value_loss           | 1.81         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 379         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002008463 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.535      |\n",
      "|    explained_variance   | 0.0589      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00635    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.000804   |\n",
      "|    value_loss           | 1.16        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 377          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037366855 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.534       |\n",
      "|    explained_variance   | 0.76         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.23         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    value_loss           | 9.07         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 377          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061147558 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.531       |\n",
      "|    explained_variance   | 0.252        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0315       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00107     |\n",
      "|    value_loss           | 0.427        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 376          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025806294 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.854        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0602       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    value_loss           | 3.62         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005967319 |\n",
      "|    clip_fraction        | 0.0353      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.52       |\n",
      "|    explained_variance   | 0.0464      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00974     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00164    |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 376          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047595114 |\n",
      "|    clip_fraction        | 0.0496       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.531       |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.24         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0154      |\n",
      "|    value_loss           | 6.58         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010490572 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.51       |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00291    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 375          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055620987 |\n",
      "|    clip_fraction        | 0.0502       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.0362       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00435     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    value_loss           | 0.0412       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 374          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070077325 |\n",
      "|    clip_fraction        | 0.0555       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.335        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0119       |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    value_loss           | 0.0288       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 374        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 136        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00568886 |\n",
      "|    clip_fraction        | 0.0387     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.505     |\n",
      "|    explained_variance   | -0.00443   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00992   |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.00173   |\n",
      "|    value_loss           | 0.0175     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1aa24794b00>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=50_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d202dc9-2332-427a-9785-e2966130b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"CartPole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a518bd4-5c11-47ee-bd58-7085a0aff67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e121e2ad-7fa7-48cd-a40b-b43cc49fcc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(\"CartPole\", env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad982f4a-aaa7-4660-843b-5d94b430c1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchgang: 0, Score: 101.0\n",
      "Durchgang: 1, Score: 101.0\n",
      "Durchgang: 2, Score: 101.0\n",
      "Durchgang: 3, Score: 101.0\n",
      "Durchgang: 4, Score: 101.0\n"
     ]
    }
   ],
   "source": [
    "durchgaenge = 5\n",
    "for d in range(durchgaenge):\n",
    "    state = env.reset()  # Am Anfang von jedem Durchgang wird die Umgebung zurückgesetzt\n",
    "    score = 0  # Summiert die Belohnung nach jedem Step auf\n",
    "    done = False\n",
    "    \n",
    "    while not done:  # Führe die Umgebung aus, bis die step Methode True zurück gibt\n",
    "        env.render()\n",
    "        if len(state) == 2:\n",
    "            action, _ = model.predict(state[0])\n",
    "        else:\n",
    "            action, _ = model.predict(state)\n",
    "        state, reward, done, term, info = env.step(action)  # Führe die Umgebung einmal aus\n",
    "        score += reward\n",
    "\n",
    "        if score > 100:\n",
    "            break\n",
    "    print(f\"Durchgang: {d}, Score: {score}\")\n",
    "env.close()  # Fenster schließen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac13f2fa-c3ad-421a-9d35-e982d3b0ea9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
